{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from scipy.special import gammainc, gammaincinv\n",
    "from sedpy.observate import load_filters, getSED\n",
    "from scipy.integrate import cumtrapz\n",
    "from scipy.stats import gaussian_kde\n",
    "import scipy.stats as stats\n",
    "from getdist import plots, MCSamples\n",
    "import matplotlib as mpl\n",
    "from astropy.cosmology import WMAP9\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tqdm\n",
    "from tqdm import trange\n",
    "tfb = tfp.bijectors\n",
    "tfd = tfp.distributions\n",
    "tfkl = tf.keras.layers\n",
    "tfk = tf.keras\n",
    "\n",
    "from sfh import *\n",
    "\n",
    "columnwidth = 20 # cm\n",
    "aspect = 1.67\n",
    "pts_per_inch = 72.27\n",
    "inch_per_cm = 2.54\n",
    "width = columnwidth/inch_per_cm\n",
    "plt.rcParams.update({'figure.figsize': [width, width / aspect],\n",
    "                                'backend': 'pdf',\n",
    "                                'font.size': 14,\n",
    "                                'legend.fontsize': 14,\n",
    "                                'legend.frameon': False,\n",
    "                                'legend.loc': 'best',\n",
    "                                'lines.markersize': 3,\n",
    "                                'lines.linewidth': 2,\n",
    "                                'axes.linewidth': .5,\n",
    "                                'axes.edgecolor': 'black'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_prior(theta):\n",
    "    \n",
    "    # f_sf_start\n",
    "    if theta[0] < 0 or theta[0] > 1.:\n",
    "        return 0\n",
    "    # tau\n",
    "    elif theta[1] < np.log(0.1) or theta[1] > np.log(100.):\n",
    "        return 0\n",
    "    # f_sf_trunc\n",
    "    elif theta[2] < 0 or theta[2] > 1.:\n",
    "        return 0\n",
    "    # sf_slope_phi\n",
    "    elif np.abs(theta[3]) > np.pi/2.:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def proposal(n):\n",
    "    \n",
    "    f_sf_start = np.random.uniform(0, 1, n)\n",
    "    lntau = np.random.uniform(np.log(0.1), np.log(100.), n)\n",
    "    f_sf_trunc = np.random.uniform(0, 1, n)\n",
    "    sf_slope_phi = np.random.uniform(-np.pi/2., np.pi/2., n)\n",
    "\n",
    "    return np.column_stack([f_sf_start, lntau, f_sf_trunc, sf_slope_phi])\n",
    "\n",
    "def importance_resample(theta, weights, N, tuniv, target):\n",
    "    \n",
    "    neff = 1./sum(weights**2)\n",
    "    scott = np.exp(np.log(sum(weights**2))/(theta.shape[-1]+4.))\n",
    "    L = np.linalg.cholesky(scott*np.cov(theta, rowvar=0, aweights=weights) + np.eye(theta.shape[-1])*1e-8)\n",
    "    theta_ = theta[np.random.choice(np.arange(0, len(theta)), size=N, p=weights),:] + np.array([np.dot(L, np.random.normal(0, 1, theta.shape[-1])) for _ in range(N)])\n",
    "    hp = [hard_prior(theta_[i,:]) for i in range(len(theta_))]\n",
    "    theta_ = theta_[np.where(np.array(hp)==1)[0],:]\n",
    "\n",
    "    sSFR = compute_sSFR(theta_, tuniv)\n",
    "\n",
    "    theta = theta_[sSFR > 0]\n",
    "    sSFR = sSFR[sSFR > 0]\n",
    "    log10_sSFR_pdf = gaussian_kde(np.log10(sSFR))\n",
    "    weights = target.pdf(np.log10(sSFR))/log10_sSFR_pdf.pdf(np.log10(sSFR))\n",
    "    weights = weights/np.sum(weights)\n",
    "    \n",
    "    return theta, sSFR, log10_sSFR_pdf, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SFH prior matching using normalizing flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create MAF and bijector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bijector\n",
    "n_params = 4\n",
    "lower = np.array([0, np.log(0.1), 0, -np.pi/2.]).astype(np.float64)\n",
    "width = np.array([1, np.log(100.) - np.log(0.1), 1., np.pi]).astype(np.float64)\n",
    "\n",
    "bijector = tfb.Chain([tfb.Blockwise([tfb.Invert(tfb.NormalCDF()) for i in range(n_params)]), \n",
    "                 tfb.Blockwise([tfb.Scale(1./width[i]) for i in range(n_params)]), \n",
    "                 tfb.Blockwise([tfb.Shift(-lower[i]) for i in range(n_params)])])\n",
    "\n",
    "\n",
    "# build the MAF\n",
    "\n",
    "# chain of bijective transforms\n",
    "n_mades = 5\n",
    "n_params = 4\n",
    "mades = [tfb.AutoregressiveNetwork(params=2, hidden_units=[50, 50], activation=tf.tanh, input_order='random') for i in range(n_mades)]\n",
    "bij = tfb.Chain([ tfb.MaskedAutoregressiveFlow(mades[i]) for i in range(n_mades)])\n",
    "base = tfd.Blockwise([tfd.Normal(loc=0, scale=1) for i in range(n_params)])\n",
    "maf = tfd.TransformedDistribution(base, bijector=bij)\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
    "\n",
    "# training step function\n",
    "def train_step_samples(x, w):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = -tf.reduce_mean(w*maf.log_prob(x))\n",
    "    gradients = tape.gradient(loss, maf.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, maf.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the MAF to match some default SFH prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of samples\n",
    "N = 100000\n",
    "\n",
    "# target density\n",
    "z = 1.\n",
    "tuniv = WMAP9.age(z).value\n",
    "mu_sSFR = (1e-10)*(1+z)**2.1\n",
    "target = stats.norm(loc=np.log10(mu_sSFR), scale=0.5)\n",
    "#target = stats.uniform(loc=-11, scale=3)\n",
    "log10_sfr_sf = target.rvs(N)\n",
    "\n",
    "# initial proposal draws\n",
    "theta = proposal(N)\n",
    "\n",
    "# compute sSFR for each \\theta and weights\n",
    "sSFR = compute_sSFR(theta, tuniv)\n",
    "theta = theta[sSFR > 0]\n",
    "sSFR = sSFR[sSFR > 0]\n",
    "log10_sSFR_pdf = gaussian_kde(np.log10(sSFR))\n",
    "weights = target.pdf(np.log10(sSFR))/log10_sSFR_pdf.pdf(np.log10(sSFR))\n",
    "weights = weights/np.sum(weights)\n",
    "\n",
    "# importance re-sampling step\n",
    "theta, sSFR, log10_sSFR_pdf, weights = importance_resample(theta, weights, N, tuniv, target)\n",
    "\n",
    "# plot the matched distribution\n",
    "plt.hist(np.log10(sSFR), bins = 100, density=True, alpha=0.5)\n",
    "plt.hist(log10_sfr_sf, bins = 100, density=True, alpha=0.5)\n",
    "x = np.linspace(min(log10_sfr_sf), max(log10_sfr_sf), 200)\n",
    "y = target.pdf(x)\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, log10_sSFR_pdf(x))\n",
    "plt.xlabel(r'$\\mathrm{log}_{10}(sSFR)$')\n",
    "plt.title('redshift z={}'.format(z))\n",
    "plt.show()\n",
    "\n",
    "# biject the samples for training the MAF\n",
    "phi = bijector.forward(theta.astype(np.float64)).numpy().astype(np.float32)\n",
    "\n",
    "# train the MAF\n",
    "epochs = 300\n",
    "pbar = tqdm.tnrange(epochs, desc=\"Iterations\")\n",
    "for epoch in pbar:\n",
    "    pbar.set_postfix(loss=train_step_samples(phi, weights).numpy())\n",
    "    \n",
    "# re-sample and re-weight\n",
    "phi = maf.sample(N).numpy().astype(np.float64)\n",
    "theta = bijector.inverse(phi).numpy()\n",
    "sSFR = compute_sSFR(theta, tuniv)\n",
    "theta = theta[sSFR > 0]\n",
    "phi = phi[sSFR > 0]\n",
    "sSFR = sSFR[sSFR > 0]\n",
    "log10_sSFR_pdf = gaussian_kde(np.log10(sSFR))\n",
    "weights = target.pdf(np.log10(sSFR))/log10_sSFR_pdf.pdf(np.log10(sSFR))\n",
    "weights = weights/np.sum(weights)\n",
    "\n",
    "# plot the matched distribution\n",
    "plt.hist(np.log10(sSFR), bins = 100, density=True, alpha=0.5)\n",
    "plt.hist(log10_sfr_sf, bins = 100, density=True, alpha=0.5)\n",
    "x = np.linspace(min(log10_sfr_sf), max(log10_sfr_sf), 200)\n",
    "y = target.pdf(x)\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, log10_sSFR_pdf(x))\n",
    "plt.xlabel(r'$\\mathrm{log}_{10}(sSFR)$')\n",
    "plt.title('redshift z={}'.format(z))\n",
    "plt.show()\n",
    "\n",
    "# re-train the MAF\n",
    "pbar = tqdm.tnrange(epochs, desc=\"Iterations\")\n",
    "for epoch in pbar:\n",
    "    pbar.set_postfix(loss=train_step_samples(phi, weights).numpy())\n",
    "    \n",
    "# re-sample and compute weights\n",
    "phi = maf.sample(N).numpy().astype(np.float64)\n",
    "theta = bijector.inverse(phi).numpy()\n",
    "sSFR = compute_sSFR(theta, tuniv)\n",
    "theta = theta[sSFR > 0]\n",
    "phi = phi[sSFR > 0]\n",
    "sSFR = sSFR[sSFR > 0]\n",
    "log10_sSFR_pdf = gaussian_kde(np.log10(sSFR))\n",
    "weights = target.pdf(np.log10(sSFR))/log10_sSFR_pdf.pdf(np.log10(sSFR))\n",
    "weights = weights/np.sum(weights)\n",
    "\n",
    "# plot the matched distribution\n",
    "plt.hist(np.log10(sSFR), bins = 100, density=True, alpha=0.5)\n",
    "plt.hist(log10_sfr_sf, bins = 100, density=True, alpha=0.5)\n",
    "x = np.linspace(min(log10_sfr_sf), max(log10_sfr_sf), 200)\n",
    "y = target.pdf(x)\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, log10_sSFR_pdf(x))\n",
    "plt.xlabel(r'$\\mathrm{log}_{10}(sSFR)$')\n",
    "plt.title('redshift z={}'.format(z))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the matched prior as a function of redshift (compare to MIZUKI prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = np.linspace(0, 2, 11)\n",
    "for z in zs:\n",
    "    \n",
    "    tuniv = WMAP9.age(z).value\n",
    "    mu_sSFR = (1e-10)*(1+z)**2.1\n",
    "    target_ = stats.norm(loc=np.log10(mu_sSFR), scale=0.3)\n",
    "    \n",
    "    phi = maf.sample(N).numpy().astype(np.float64)\n",
    "    theta = bijector.inverse(phi).numpy()\n",
    "    sSFR = compute_sSFR(theta, tuniv)\n",
    "    \n",
    "    theta = theta[sSFR > 0]\n",
    "    phi = phi[sSFR > 0]\n",
    "    sSFR = sSFR[sSFR > 0]\n",
    "    log10_sSFR_pdf = gaussian_kde(np.log10(sSFR))\n",
    "    \n",
    "    plt.hist(np.log10(sSFR), bins = 100, density=True, alpha=0.5)\n",
    "    plt.hist(log10_sfr_sf, bins = 100, density=True, alpha=0.5)\n",
    "    x = np.linspace(min(log10_sfr_sf), max(log10_sfr_sf), 200)\n",
    "    y = target.pdf(x)\n",
    "    plt.plot(x, y)\n",
    "    plt.plot(x, target_.pdf(x))\n",
    "    plt.plot(x, log10_sSFR_pdf(x))\n",
    "    plt.xlabel(r'$\\mathrm{log}_{10}(sSFR)$')\n",
    "    plt.title('redshift z={}'.format(z))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate parameter draws from the prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 12.78it/s]\n"
     ]
    }
   ],
   "source": [
    "n_samples = 100000\n",
    "n_batch = 64\n",
    "\n",
    "# interpolator for tuniv\n",
    "tuniv_ = InterpolatedUnivariateSpline(np.linspace(0, 2.5, 100), WMAP9.age(np.linspace(0, 2.5, 100)).value)\n",
    "\n",
    "for i in trange(n_batch):\n",
    "    \n",
    "    # generate SFH parameters from matched prior...\n",
    "    \n",
    "    # star-forming galaxies\n",
    "    phi = maf.sample(n_samples).numpy().astype(np.float64)\n",
    "    theta_sfh_sf = bijector.inverse(phi).numpy() # star-forming galaxies\n",
    "    \n",
    "    # quiescent galaxies\n",
    "    theta_sfh_q = proposal(10 * n_samples)\n",
    "    \n",
    "    # generate other parameter draws\n",
    "    z_sf = np.random.uniform(0, 2.5, n_samples)\n",
    "    z_q = np.random.uniform(0, 2.5, 10 * n_samples)\n",
    "    log10Z = np.random.uniform(-1.98, 0.19, 2 * n_samples)\n",
    "    dust2 = np.random.uniform(0, 2, 2 * n_samples)**2\n",
    "    dust_index = np.random.uniform(-1, 0.4, 2 * n_samples)\n",
    "    \n",
    "    # sort out the quiescent SFHs\n",
    "    sSFR_q = compute_sSFR(theta_sfh_q, tuniv_(z_q))\n",
    "    quiescent = sSFR_q < 1e-11\n",
    "    theta_sfh_q = theta_sfh_q[quiescent, :]\n",
    "    z_q = z_q[quiescent]\n",
    "    if theta_sfh_q.shape[0] < n_samples:\n",
    "        print('not enough samples!')\n",
    "    theta_sfh_q = theta_sfh_q[0:n_samples, :]\n",
    "    z_q = z_q[0:n_samples]\n",
    "    \n",
    "    # stack SFH parts\n",
    "    z = np.concatenate([z_sf, z_q])\n",
    "    theta_sfh = np.concatenate([theta_sfh_sf, theta_sfh_q])\n",
    "    \n",
    "    # stack the samples and save them to file\n",
    "    theta = np.column_stack([np.column_stack([z, log10Z, dust2, dust_index]), theta_sfh])\n",
    "    \n",
    "    # send them to file\n",
    "    np.save('training_data/parameters/parameters{}.npy'.format(i), theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
